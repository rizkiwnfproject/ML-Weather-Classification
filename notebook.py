# -*- coding: utf-8 -*-
"""notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VCsnlijTs9FXGNXIQnjCW0mbUNmMLNCq

# Laporan Proyek Machine Learning - Rizki Wahyu Nurcahyani Fajarwati
- **Nama:** Rizki Wahyu Nurcahyani Fajawrati
- **Email:** a123xbf441@devacademy.id
- **ID Dicoding:** a123xbf441

## Import Semua Packages/Library yang Digunakan
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import MinMaxScaler, Normalizer, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier

from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
from sklearn.model_selection import train_test_split

"""## Data Understanding

Baris kode dibawah ini digunakan untuk membaca file CSV bernama weather_classification_data.csv. File CSV tersebut berisi dataset cuaca yang akan digunakan untuk analisis atau pemodelan. Hasil pembacaan disimpan dalam variabel df (dataframe). Kemudian menggunakan head() untuk menampilkan 5 baris pertama dari dataframe df. Ini berguna untuk melihat struktur awal data, seperti nama kolom, tipe data, dan isi dari beberapa baris awal.
"""

df = pd.read_csv("weather_classification_data.csv")
print("Dataset Shape:", df.shape)
print(df.head())

"""Descriptive merupakan fungsi yang digunakan untuk menghasilkan statistik deskriptif dari kolom-kolom numerik di dalam dataframe df.
Statistik yang ditampilkan mencakup:
- count: jumlah nilai yang tidak kosong (non-NaN),
- mean: nilai rata-rata,
- std: standar deviasi (penyebaran data),
- min: nilai minimum,
- 25%, 50%, 75%: kuartil 1, median, dan kuartil 3,
- max: nilai maksimum.
"""

print("\nDescriptive Statistics:\n", df.describe())

"""Mengambil semua nama kolom dari dataframe df lalu menghitung berapa banyak baris dan kolom grid yang dibutuhkan agar semua fitur bisa divisualisasikan dalam 4 subplot. Kemudian membuat figure dan axes menggunakan matplotlib, lalu mengubah susunannya agar mudah diakses satu per satu. Dilakukan iterasi untuk setiap kolom dan dibuatkan histogramnya dengan judul masing-masing setiap diagramnya agar mudah untuk dibaca."""

cols = df.columns.to_list()
n_cols = 4
n_rows = -(-len(cols) // n_cols)

fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 10))
axes = axes.flatten()

for i, col in enumerate(cols):
    sns.histplot(data=df, x=col, kde=True, bins=30, color='skyblue', ax=axes[i])
    axes[i].set_title(f'Distribution of {col}')
    axes[i].set_xlabel(col)
    axes[i].set_ylabel('Frequency')

for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

cols

"""Langkah ini digunakan untuk membuat visualisasi korelasi antara fitur numerik dalam dataset, dalam bentuk heatmap. Dengan adanya langkah ini, dapat mengetahui fitur mana yang saling berkorelasi tinggi atau sangat berhubungan."""

df_selected = df[['Temperature', 'Humidity', 'Wind Speed', 'Precipitation (%)','Atmospheric Pressure','Visibility (km)', 'UV Index']]
plt.figure(figsize=(10, 8))
sns.heatmap(df_selected.corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Heatmap Korelasi antar Fitur')
plt.tight_layout()
plt.show()

"""Langkah ini digunakan untuk mengecek outlier dari fitur numerik dalam dataset menggunakan boxplot, yaitu jenis grafik statistik yang sangat efektif untuk mendeteksi nilai ekstrem. Outlier penting untuk diidentifikasi karena dapat memengaruhi rata-rata atau model machine learning."""

cols = [
    'Temperature',
    'Humidity',
    'Wind Speed',
    'Precipitation (%)',
    'Atmospheric Pressure',
    'UV Index',
    'Visibility (km)'
    ]

fig, axes = plt.subplots(4, 2, figsize=(14, 10))
axes = axes.flatten()

for i, col in enumerate(cols):
    sns.boxplot(data=df, x=col, ax=axes[i], color='lightgreen')
    axes[i].set_title(f'Outlier - {col}')
    axes[i].set_xlabel(col)

plt.tight_layout()
plt.show()

"""## Data Preparation

### Data Preprocessing

Kode ini digunakan untuk mengecek apakah di dalam kolom yang ada di df terdapat missing value, kemudian di print atau ditampilkan
"""

missing_values = df.isnull().sum()
print(missing_values)

"""Kode ini digunakan untuk mengecek atau memeriksa tipe data dari setiap kolom yang ada di variabel df, dan terdapat 3 tipe data yaitu float, int, dan object."""

data_types = df.dtypes
print(data_types)

"""#### Menghapus Outlier Data

Kode ini mendefinisikan dan menerapkan fungsi untuk menghapus outlier dari dataset menggunakan metode IQR (Interquartile Range), yaitu salah satu metode paling umum dalam statistik. Untuk menghapusnya sendiri seperti menghapus baris-baris yang mengandung nilai outlier pada kolom-kolom yang ditentukan, berdasarkan rumus IQR. Jika sebelum dihapus datanya ada 13.200 setelah dihapus outliernya datanya menjadi 11586.
"""

def remove_outliers_iqr(df, columns):
    for col in columns:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]
    return df

df_cleaned = remove_outliers_iqr(df, cols)

print("Data setelah menghapus outlier:", df_cleaned.shape)

cols = [
    'Temperature',
    'Humidity',
    'Wind Speed',
    'Precipitation (%)',
    'Atmospheric Pressure',
    'UV Index',
    'Visibility (km)'
    ]

fig, axes = plt.subplots(4, 2, figsize=(14, 10))
axes = axes.flatten()

for i, col in enumerate(cols):
    sns.boxplot(data=df_cleaned, x=col, ax=axes[i], color='lightgreen')
    axes[i].set_title(f'Outlier - {col}')
    axes[i].set_xlabel(col)

plt.tight_layout()
plt.show()

"""Kode di bawah ini digunakan untuk mengubah data kategorikal menjadi data numerik agar bisa digunakan dalam algoritma machine learning yang hanya menerima input angka. Kolom-kolom 'Weather Type', 'Season', 'Location', dan 'Cloud Cover' dikodekan ke bentuk numerik. Di sini digunakan Label Encoding dari scikit-learn, yang mengubah setiap nilai unik menjadi angka (misalnya: ['Sunny', 'Rainy', 'Cloudy'] jadi [2, 1, 0])."""

label_cols = ['Weather Type', 'Season', 'Location', 'Cloud Cover']
le = LabelEncoder()

for col in label_cols:
    df_cleaned[col] = le.fit_transform(df_cleaned[col])

"""Kode ini digunakan untuk memisahkan fitur (X) dan target (y), lalu membagi data menjadi data latih dan data uji â€” langkah penting dalam proses pembuatan model machine learning."""

X = df_cleaned.drop('Weather Type', axis=1)
y = df_cleaned['Weather Type']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""Kode ini menggunakan MinMaxScaler dari library scikit-learn untuk menstandarisasi atau menskalakan fitur dalam dataset agar berada dalam rentang tertentu, biasanya antara 0 dan 1."""

scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

X_train

"""## Modelling

Kode ini digunakan untuk membuat sebuah dictionary bernama models yang berisi tiga model machine learning berbeda. Setiap model diinisialisasi dengan parameter tertentu. Model yang digunakan antara lain : Logistic Regression, Decision Tree, XGBoost.
"""

models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Decision Tree": DecisionTreeClassifier(),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
}

"""Kode ini melakukan pelatihan dan prediksi untuk setiap model yang ada dalam dictionary models, dan menyimpan hasilnya ke dalam dictionary trained_models dan predictions."""

trained_models = {}
predictions = {}
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    trained_models[name] = model
    predictions[name] = y_pred

"""### Evaluasi

Kode ini melakukan evaluasi untuk setiap model yang telah dilatih, dengan menampilkan laporan klasifikasi dan confusion matrix. Pertama, untuk setiap model, kode ini mengambil hasil prediksi dan model yang telah dilatih. Kemudian, menampilkan laporan klasifikasi (precision, recall, F1-score) dengan menggunakan classification_report, serta confusion matrix untuk melihat distribusi prediksi dan kesalahan klasifikasi. Confusion matrix ditampilkan dalam bentuk plot dengan label yang sesuai. Hasil evaluasi ini memberikan gambaran lengkap mengenai kinerja tiap model pada data uji.
"""

for name in trained_models:
    print(f"\n=== Evaluation for {name} ===")

    y_pred = predictions[name]
    model = trained_models[name]

    print("Classification Report:")
    print(classification_report(y_test, y_pred, zero_division=0))

    cm = confusion_matrix(y_test, y_pred, labels=model.classes_)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)

    plt.figure(figsize=(6, 4))
    disp.plot(cmap='Blues', values_format='d')
    plt.title(f'Confusion Matrix - {name}')
    plt.show()

"""## Hasil

Hasil evaluasi menunjukkan bahwa ketiga model (Logistic Regression, Decision Tree, dan XGBoost) memiliki kinerja yang sangat baik.
- Logistic Regression memiliki akurasi 94%, dengan precision, recall, dan F1-score yang konsisten tinggi di seluruh kelas, meskipun sedikit lebih rendah dibandingkan Decision Tree dan XGBoost.
- Decision Tree dan XGBoost keduanya memiliki akurasi 97%, dengan precision, recall, dan F1-score yang hampir sempurna di semua kelas.
- XGBoost sedikit lebih unggul dalam precision untuk beberapa kelas. Secara keseluruhan, Decision Tree dan XGBoost memberikan kinerja terbaik dengan nilai yang sangat mirip, namun XGBoost sedikit lebih baik dalam beberapa metrik.
"""